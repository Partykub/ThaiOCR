#!/usr/bin/env python3
"""
‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Thai OCR Dataset
‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á
"""

import os
import subprocess
import sys

def run_command(cmd, description):
    """‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•"""
    print(f"\nüöÄ {description}")
    print(f"‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: {cmd}")
    print("-" * 50)
    
    result = subprocess.run(cmd, shell=True, capture_output=False)
    if result.returncode == 0:
        print(f"‚úÖ {description} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
    else:
        print(f"‚ùå {description} ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß!")
        return False
    return True

def main():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(os.path.dirname(base_dir))  # ‡πÑ‡∏õ‡∏ó‡∏µ‡πà root ‡∏Ç‡∏≠‡∏á project
    
    print("üéØ ‡∏™‡∏£‡πâ‡∏≤‡∏á Thai OCR Dataset")
    print("=" * 50)
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå thai_text_generator.py ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if not os.path.exists("thai-letters/thai_text_generator.py"):
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå thai_text_generator.py")
        return
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ corpus ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if not os.path.exists("thai-letters/thai_corpus.txt"):
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå thai_corpus.txt")
        return
    
    # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏ô corpus
    with open("thai-letters/thai_corpus.txt", 'r', encoding='utf-8') as f:
        corpus_lines = sum(1 for line in f)
    
    print(f"üìä ‡∏û‡∏ö corpus {corpus_lines:,} ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏ï‡πà‡∏≤‡∏á‡πÜ
    datasets = [
        {
            "name": "Dataset ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (500 ‡∏†‡∏≤‡∏û)",
            "cmd": "python thai-letters/thai_text_generator.py -c thai-letters/thai_corpus.txt -n 500 -o thai-letters/generated_text_samples",
            "output": "thai-letters/generated_text_samples"
        },
        {
            "name": f"Dataset ‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î ({corpus_lines:,} ‡∏†‡∏≤‡∏û)",
            "cmd": f"python thai-letters/thai_text_generator.py -c thai-letters/thai_corpus.txt -n {corpus_lines} -o thai-letters/full_corpus_dataset",
            "output": "thai-letters/full_corpus_dataset"
        }
    ]
    
    for dataset in datasets:
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ dataset ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if os.path.exists(dataset["output"]):
            response = input(f"\n‚ùì {dataset['name']} ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà? (y/N): ")
            if response.lower() != 'y':
                print(f"‚è≠Ô∏è  ‡∏Ç‡πâ‡∏≤‡∏° {dataset['name']}")
                continue
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset
        success = run_command(dataset["cmd"], dataset["name"])
        if not success:
            continue
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        if os.path.exists(f"{dataset['output']}/images"):
            import glob
            images = glob.glob(f"{dataset['output']}/images/*.jpg")
            print(f"üì∑ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {len(images):,} ‡∏†‡∏≤‡∏û")
            
        if os.path.exists(f"{dataset['output']}/labels.txt"):
            with open(f"{dataset['output']}/labels.txt", 'r', encoding='utf-8') as f:
                labels = sum(1 for line in f)
            print(f"üè∑Ô∏è  ‡∏™‡∏£‡πâ‡∏≤‡∏á labels: {labels:,} ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
    
    print("\nüéâ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
    print("üìÅ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå:")
    print("   - thai-letters/thai_ocr_dataset/ (5,000 ‡∏†‡∏≤‡∏û - ‡πÄ‡∏î‡∏¥‡∏°)")
    print("   - thai-letters/generated_text_samples/ (500 ‡∏†‡∏≤‡∏û)")
    print(f"   - thai-letters/full_corpus_dataset/ ({corpus_lines:,} ‡∏†‡∏≤‡∏û)")

if __name__ == "__main__":
    main()
